{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import flickrapi\n",
    "import folium\n",
    "import time\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credenciais (filename=\"credential.json\"):\n",
    "    current_dir = Path.cwd() # os.path.dirname(os.path.abspath(__file__))\n",
    "    credentials_path = os.path.join(current_dir, 'credentials', filename)\n",
    "\n",
    "    with open(credentials_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "        chave = data[\"CHAVE\"]\n",
    "        segredo = data[\"SEGREDO\"]\n",
    "\n",
    "    return chave, segredo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key, secret_key = credenciais()\n",
    "flickr = flickrapi.FlickrAPI(api_key, secret_key)\n",
    "\n",
    "# if not flickr:\n",
    "#     flickr.authenticate_via_browser(perms='read')\n",
    "flickr.authenticate_via_browser(perms='read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = \"-7.144126\"\n",
    "longitude = \"-34.857480\"\n",
    "raio = \"8\"\n",
    "data_inicio = \"2004-04-01\"\n",
    "data_final = \"2020-04-08\"  # Uma semana depois da data de início"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "shots = flickr.photos.search(\n",
    "    has_geo=\"1\",\n",
    "    extras=\"geo, owner_name, date_taken\",  # Adicionando extras para obter a data em que a foto foi tirada\n",
    "    privacy_filter=\"1\",\n",
    "    per_page=\"250\",  # Há um limite máximo de 250 fotos por página\n",
    "    min_taken_date=data_inicio,\n",
    "    max_taken_date=data_final,\n",
    "    radius_units=\"km\",\n",
    "    radius=raio,\n",
    "    lat=latitude,\n",
    "    lon=longitude\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos = shots.find('photos').findall('photo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for photo in photos:\n",
    "    photo_id = photo.attrib['id']\n",
    "    owner_name = photo.attrib['ownername']\n",
    "    date_taken = photo.attrib['datetaken']\n",
    "    latitude = photo.attrib['latitude']\n",
    "    longitude = photo.attrib['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready loading history.\n"
     ]
    }
   ],
   "source": [
    "imeframe = 43200                           # Unixtime for 12 hours == 60seconds *60minutes *24hours; This will query the API for a certain time. Increase this number if there aren't any decent results...\n",
    "one_week = 604800                           # Unixtime for one week == 60seconds *60minutes *24hours* 7days (Scope is too large to be used - only a fraction of the data that is available gets returned)\n",
    "                                            # Need a Unix convertor?: http://www.unixtimestamp.com/\n",
    "                                            # Alternatively you can use the built in time module of Python.\n",
    "\n",
    "raw_file = open(\"raw_data.csv\", \"a\")        # where your datapoints will be stored at\n",
    "history = open(\"done_ids.txt\", \"r\")         # all photo_ID's that have been added in the past.\n",
    "\n",
    "donepre = history.readlines()               # Preventing adding the same photo twice.\n",
    "history.close()\n",
    "\n",
    "done = []\n",
    "for item in donepre:\n",
    "    item = item.strip()\n",
    "    done.append(item)\n",
    "\n",
    "donepids = open(\"done_ids.txt\", \"a\")\n",
    "print(\"Ready loading history.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #################THESE ARE YOUR UPPER AND LOWER LIMITS - HARDCODED IN THE SCRIPT!###############\n",
    "\n",
    "data_inicio = 954558000            # 01/04/2000        # Bottom time limit, we shall call for all photo's that are uploaded after this timepoint.\n",
    "data_final = data_inicio + one_week # 1711940400            # 01/04/2024     # Upper time limit for our small call, the while loop will keep using this untill it reaches the enddate.)\n",
    "\n",
    "dia_atual = time.time()                   #gets the current time in unixcode.\n",
    "dia_atual = int(dia_atual)\n",
    "\n",
    "#dia_atual = 1376284800                    #overwrites curtime with a value set in the past. You can comment this line out of you wish to go from point X to now. Carefull however, as calling flickr too long on one end may cause connection termination.\n",
    "#Moet nog lopen!! 29/3/2017\n",
    "\n",
    "        ################City variables: Latitude, Longitude, radius(in KM) HARDCODED, replace according to the example and leave within quotes!##############\n",
    "latitude = \"-7.144126\"\n",
    "longitude = \"-34.857480\"\n",
    "raio = \"8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data = True\n",
    "one_week = 604800\n",
    "total_pages = 1\n",
    "\n",
    "while add_data:\n",
    "\n",
    "    page = 1\n",
    "    startdate = str(data_inicio)\n",
    "    enddate = str(data_final)\n",
    "    shots = flickr.photos.search(page=str(page),\n",
    "                                 has_geo=\"1\",\n",
    "                                 extras=\"geo, owner_name\",\n",
    "                                 privacy_filter=\"1\",\n",
    "                                 per_page=\"250\",\n",
    "                                 min_upload_date=startdate,\n",
    "                                 max_upload_date=enddate,\n",
    "                                 radius_units=\"km\",\n",
    "                                 radius=raio,\n",
    "                                 lat=latitude,\n",
    "                                 lon=longitude)\n",
    "    \n",
    "    parsed = shots.find('photos').findall('photo')\n",
    "    # parsed = json.loads(shots.decode('utf-8'))          #returns a dictionary\n",
    "    for key in parsed:\n",
    "        part = parsed[\"photos\"]\n",
    "        total_pages =  part[\"pages\"]\n",
    "\n",
    "    # print(f\"There are {total_pages} pages returned by flickr\")\n",
    "    #print data_final\n",
    "    while page <= total_pages:\n",
    "        shots = flickr.photos.search(page=str(page),\n",
    "                                     has_geo=\"1\",\n",
    "                                     extras=\"geo, owner_name\",\n",
    "                                     privacy_filter=\"1\",\n",
    "                                     per_page=\"250\",\n",
    "                                     min_upload_date=startdate,\n",
    "                                     max_upload_date=enddate,\n",
    "                                     radius_units=\"km\",\n",
    "                                     radius=raio,\n",
    "                                     lat=latitude,\n",
    "                                     lon=longitude)\n",
    "        \n",
    "        parsed = shots.find('photos').findall('photo')\n",
    "        # parsed = json.loads(shots.decode('utf-8'))\n",
    "# \"\"\"\n",
    "#         for key in parsed:\n",
    "#             x =  type(parsed[key])\n",
    "#             if str(x) == \"<type 'dict'>\":   \n",
    "#                 newdict = parsed[key]       \n",
    "#                 for key in newdict:\n",
    "#                     y =  type(newdict[key])\n",
    "#                     if str(y) == \"<type 'list'>\":\n",
    "#                         for item in newdict[key]:\n",
    "#                             for key in item:\n",
    "#                                 photo_id = str(item[\"id\"].encode(\"utf-8\"))\n",
    "\n",
    "#                             if photo_id not in done:\n",
    "#                                 done.append(photo_id)\n",
    "#                                 longt = str(item[\"longitude\"])\n",
    "#                                 lat = str(item[\"latitude\"])\n",
    "#                                 user_internal_id = str(item[\"owner\"].encode(\"utf-8\"))\n",
    "#                                 user_name = str(item[\"ownername\"].encode(\"utf-8\"))\n",
    "#                                 visit = \"https://www.flickr.com/photos/\" + user_internal_id + \"/\" + photo_id\n",
    "#                                 #print lat\n",
    "#                                 #print longt\n",
    "\n",
    "#                                 raw_file.write('\"'+ photo_id + '\";\"' + user_internal_id + '\";\"' + user_name + '\";\"' + lat + '\";\"' + longt + '\";\"' + visit + '\"\\n')\n",
    "#                                 donepids.write(photo_id + \"\\n\")\n",
    "#                             else:\n",
    "#                                 pass\n",
    "#                                 #print \"double\"\n",
    "\n",
    "\n",
    "\n",
    "#         print(str(page) + \" of \" + str(total_pages) + \" is done.\")\n",
    "#         page = page+1\n",
    "\n",
    "#         #print \"page UP\"\n",
    "#         #print \"taking new data\"\n",
    "# \"\"\"\n",
    "    \n",
    "    data_inicio = data_inicio + one_week\n",
    "    data_final = data_final + one_week\n",
    "    #print data_inicio\n",
    "    print(data_final)\n",
    "\n",
    "    if dia_atual < data_inicio:\n",
    "        add_data = False\n",
    "\n",
    "#\n",
    "raw_file.close()                            #Closing the CSV file\n",
    "donepids.close()                            #Closing the progress tracker file\n",
    "\n",
    "print(\"Process complete\")\n",
    "\n",
    "# ext = raw_input(\"Press enter to terminate the program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = 1\n",
    "startdate = str(data_inicio)\n",
    "enddate = str(data_final)\n",
    "shots = flickr.photos.search(page=str(page),\n",
    "                            has_geo=\"1\",\n",
    "                            extras=\"geo, owner_name\",\n",
    "                            privacy_filter=\"1\",\n",
    "                            per_page=\"250\",\n",
    "                            min_upload_date=startdate,\n",
    "                            max_upload_date=enddate,\n",
    "                            radius_units=\"km\",\n",
    "                            radius=raio,\n",
    "                            lat=latitude,\n",
    "                            lon=longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "parsed = shots.find('photos').findall('photo')\n",
    "# parsed = json.loads(shots.decode('utf-8'))          #returns a dictionary\n",
    "\n",
    "for key in parsed:\n",
    "    part = parsed[\"photos\"]\n",
    "    total_pages =  part[\"pages\"]\n",
    "\n",
    "print(len(parsed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
